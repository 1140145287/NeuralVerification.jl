{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating METADATA...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mComputing changes...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage JuMP is already installed\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage GLPKMathProgInterface is already installed\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mNo packages to install, update or remove\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "Pkg.update() \n",
    "Pkg.add(\"JuMP\")\n",
    "Pkg.add(\"GLPKMathProgInterface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using MathProgBase\n",
    "using GLPKMathProgInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"util.jl\")\n",
    "include(\"network.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(Layer[Layer([1.5, 1.5], [1.0; 1.0]), Layer([2.5, 2.5], [2.0 2.0; 2.0 2.0]), Layer([3.5], [3.0 3.0])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in neural networks\n",
    "large_nnet = read_nnet(\"ACASXU_nnet_1.txt\")\n",
    "small_nnet = read_nnet(\"small_nnet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_input_constraints (generic function with 2 methods)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_input_constraints(nnet::Network, m::Model, upperBounds::Vector{Float64}, lowerBounds::Vector{Float64}, \n",
    "                               A::Matrix{Float64} = [eye(length(upperBounds)); -eye(length(lowerBounds))])\n",
    "    n_inputs = size(nnet.layers[1].weights)[2]\n",
    "    b = [upperBounds; -lowerBounds]\n",
    "    x_in = @variable(m, [1:n_inputs])\n",
    "    @constraint(m, A*x_in .<= b)\n",
    "    return x_in\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_output_constraints (generic function with 2 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_output_constraints(nnet::Network, m::Model, upperBounds::Vector{Float64}, lowerBounds::Vector{Float64}, \n",
    "                                A::Matrix{Float64}=[eye(length(upperBounds)); -eye(length(lowerBounds))])\n",
    "    n_outputs = size(nnet.layers[length(nnet.layers)].weights)[1]\n",
    "    b = [upperBounds; -lowerBounds]\n",
    "    x_out = @variable(m, [1:n_outputs])\n",
    "    @constraint(m, A * x_out .<= b)\n",
    "    return x_out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_network_constraints (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_network_constraints(nnet::Network, m::Model,  x_in::Array{JuMP.Variable,1}, x_out::Array{JuMP.Variable,1})\n",
    "    layers = nnet.layers\n",
    "    M = 1 # define reasonable M?\n",
    "    \n",
    "    x_net = @variable(m, [i=1:length(layers), j=1:length(layers[i].bias)]) \n",
    "    deltas = @variable(m, [i=1:length(layers), j=1:length(layers[i].bias)]) \n",
    "\n",
    "    for i in 1:length(layers) - 1\n",
    "        weights = layers[i].weights\n",
    "        bias = layers[i].bias\n",
    "        \n",
    "        for j in 2:length(bias)\n",
    "            dot_prod = 1\n",
    "            if i == 1\n",
    "                dot_prod = @expression(m, [k=1:size(nnet.layers[1].weights)[2]], sum(weights[j,k] * x_in[k]))\n",
    "            else\n",
    "                dot_prod = @expression(m, [k=1:length(layers[i-1].bias)], sum(weights[j,k] * x_net[i-1,k]))\n",
    "            end\n",
    "            @constraint(m, x_net[i,j] .>= dot_prod + bias[j]) \n",
    "            @constraint(m, x_net[i,j] .<= dot_prod + bias[j] + M*deltas[i,j])\n",
    "            @constraint(m, x_net[i,j] >= 0)\n",
    "            @constraint(m, x_net[i,j] <= M*(1 - deltas[i,j]))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    i = length(layers)\n",
    "    weights = layers[i].weights\n",
    "    bias = layers[i].bias\n",
    "    for l in 1:length(bias)\n",
    "        dot_prod = @expression(m, [k=1:length(nnet.layers[i-1].bias)], sum(weights[l,k] * x_net[l,k]))\n",
    "        @constraint(m, x_out[l] .>= dot_prod + bias[l])\n",
    "        @constraint(m, x_out[l] .<= dot_prod + bias[l] + M*deltas[i,l])\n",
    "        @constraint(m, x_out[l] >= 0)\n",
    "        @constraint(m, x_out[l] <= M*(1 - deltas[i,l]))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for 0.0 = 54.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mNot solved to optimality, status: Infeasible\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infeasible"
     ]
    }
   ],
   "source": [
    "# should return optimal\n",
    "test_model = Model(solver = GLPKSolverLP())\n",
    "input_lower_bounds = [0.0]\n",
    "input_upper_bounds = [0.0]\n",
    "x_in = add_input_constraints(small_nnet, test_model, input_upper_bounds, input_lower_bounds)\n",
    "output_lower_bounds = [54.5]\n",
    "output_upper_bounds = [54.5]\n",
    "x_out = add_output_constraints(small_nnet, test_model, output_upper_bounds, output_lower_bounds)\n",
    "add_network_constraints(small_nnet, test_model, x_in, x_out)\n",
    "status = solve(test_model)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infeasible"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mNot solved to optimality, status: Infeasible\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# should return infeasible\n",
    "test_model = Model(solver = GLPKSolverLP())\n",
    "input_lower_bounds = [0.0]\n",
    "input_upper_bounds = [0.0]\n",
    "x_in = add_input_constraints(small_nnet, test_model, input_upper_bounds, input_lower_bounds)\n",
    "output_lower_bounds = [0.0]\n",
    "output_upper_bounds = [54.0]\n",
    "x_out = add_output_constraints(small_nnet, test_model, output_upper_bounds, output_lower_bounds)\n",
    "add_network_constraints(small_nnet, test_model, x_in, x_out)\n",
    "status = solve(test_model)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer[Layer([1.5, 1.5], [1.0; 1.0]), Layer([2.5, 2.5], [2.0 2.0; 2.0 2.0]), Layer([3.5], [3.0 3.0])]"
     ]
    }
   ],
   "source": [
    "print(small_nnet.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our model and test on small_nnet\n",
    "model = Model(solver = GLPKSolverLP()) # use GLPK LP as our solver\n",
    "\n",
    "input_lower_bounds = [0.0]\n",
    "input_upper_bounds = [0.0]\n",
    "x_in = add_input_constraints(small_nnet, input_lower_bounds, input_upper_bounds, model)\n",
    "\n",
    "output_lower_bounds = [1.0]\n",
    "output_upper_bounds = [54.5]\n",
    "x_out = add_output_constraints(small_nnet, output_lower_bounds, output_upper_bounds, model)\n",
    "\n",
    "#add_network_constraints(small_nnet, model, x_in, x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(small_nnet.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the model\n",
    "status = solve(model)\n",
    "print(model)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
