{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating METADATA...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mComputing changes...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mNo packages to install, update or remove\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage JuMP is already installed\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage GLPKMathProgInterface is already installed\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "Pkg.update() \n",
    "Pkg.add(\"JuMP\")\n",
    "Pkg.add(\"GLPKMathProgInterface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using MathProgBase\n",
    "using GLPKMathProgInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"util.jl\")\n",
    "include(\"network.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(Layer[Layer([0.22763, -0.188762, 0.0534094, -0.377861, -0.0812531, -0.588651, 0.0746065, -0.392887, -0.356303, -0.167712  …  0.221606, -0.00650873, -0.634843, -0.153833, -0.0573027, -0.109229, 0.0370344, 0.0538087, -0.44755, 0.175917], [0.0540062 0.0540062 … -0.180027 0.242194; -1.12374 -1.12374 … -0.00917929 0.055623; … ; -1.57631 -1.57631 … -0.00832176 -0.0926607; 0.620367 0.620367 … -0.0146141 0.262575]), Layer([0.08355, -0.0213261, 0.756291, -1.25082, 0.178469, -0.339158, 0.109226, -1.26214, -0.356488, -0.00829379  …  0.655079, 1.25241, 0.0390987, -0.0242382, -0.385696, -0.359071, -0.155856, 0.0285971, -0.426623, 0.780925], [-0.184202 -0.184202 … 0.337388 0.395671; 0.0171639 0.0171639 … -0.0371157 0.0196442; … ; -1.24508 -1.24508 … 0.646698 -0.159838; -0.348713 -0.348713 … -0.60238 -0.142155]), Layer([-0.408486, 1.06875, -0.101351, 0.291739, 0.361906, -1.17598, -1.08494, -0.525396, -0.485121, -0.563451  …  -0.563058, -0.217101, 0.570546, -0.523408, -1.49997, -0.261921, -0.526109, -0.00598984, -0.464336, 0.114195], [0.146062 0.146062 … -1.15657 0.515279; -1.159 -1.159 … -2.33211 -0.517898; … ; -1.14982 -1.14982 … -1.17371 0.414968; -0.684643 -0.684643 … -0.064733 -0.186417]), Layer([1.48416, -0.0392727, -0.0907838, -2.47397, -2.26864, 0.289911, 0.0849784, -0.0216935, -0.688173, -0.245358  …  -0.0413228, -0.688478, 0.0999729, 0.235693, 0.200208, 0.185322, 0.213242, -0.0363364, 0.0762837, -0.216393], [-0.775044 -0.775044 … 0.00288769 -0.0587614; -0.289933 -0.289933 … 0.0289771 0.0943521; … ; 0.124486 0.124486 … -0.0140547 0.0703901; 0.0862763 0.0862763 … 0.0219731 -0.0403008]), Layer([0.343884, -0.148704, -0.182344, 2.09282, 0.0573921, 1.07278, -3.5375, 0.290246, 1.78528, 0.570392  …  0.971201, 0.414523, 0.559316, 0.711265, -3.24478, 0.58, 0.165873, -1.29327, -0.331041, -0.654165], [-0.169473 -0.169473 … -0.0158796 0.271254; 0.143577 0.143577 … -0.00813101 -0.193434; … ; 0.233909 0.233909 … -0.0408955 -1.33666; 0.19239 0.19239 … 0.0402966 -0.291227]), Layer([-0.430061, -0.0245742, -1.85737, -0.0138152, 0.419247, -0.213587, 0.16007, 0.741838, 0.00846945, -0.726034  …  0.36664, 1.18725, -7.0066, 0.864816, -4.08665, 0.190657, 0.438984, -0.664789, -0.114347, 0.121706], [0.0198897 0.0198897 … -0.556117 -0.321128; -0.12478 -0.12478 … 0.0824242 0.0293015; … ; -0.283984 -0.283984 … 0.0293453 -0.0325373; 0.0114592 0.0114592 … -0.0156882 -0.00548695]), Layer([-0.0102815, -0.0158668, -0.0154823, -0.015336, -0.0148281], [-0.0010049 -0.0010049 … -0.00114841 0.0116412; -0.00160923 -0.00160923 … -0.0515162 0.011273; … ; 0.00386038 0.00386038 … -0.0582468 -0.0100225; 0.032974 0.032974 … -0.00340823 0.0212921])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in neural networks\n",
    "small_nnet = read_nnet(\"small_nnet.txt\")\n",
    "large_nnet = read_nnet(\"ACASXU_nnet_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_input_constraints (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_input_constraints(nnet::Network, inputs::Matrix{Float64}, m::Model) # change inputs to vector here as well\n",
    "    n_inputs = size(nnet.layers[1].weights)[2]\n",
    "    @variable(m, x_in[1:n_inputs])\n",
    "    @constraint(m, constr_in[i=1:n_inputs], x_in[i] == inputs[i])    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{JuMP.ConstraintRef,1}:\n",
       " x_in[1] = 1\n",
       " x_in[2] = 2\n",
       " x_in[3] = 3\n",
       " x_in[4] = 4\n",
       " x_in[5] = 5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test add input constraints\n",
    "inputs = [1.0 2.0 3.0 4.0 5.0] # change inputs to set of vectors - type Ax <= b\n",
    "m = Model(solver = GLPKSolverLP())\n",
    "add_input_constraints(large_nnet, inputs, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_output_constraints (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_output_constraints(nnet::Network, outputs::Matrix{Float64}, m::Model)\n",
    "    n_layers = length(nnet.layers)\n",
    "    n_outputs = size(nnet.layers[n_layers].weights)[1]\n",
    "    @variable(m, x_out[1:n_outputs])\n",
    "    @constraint(m, constr_out[i=1:n_outputs], x_out[i] == outputs[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{JuMP.ConstraintRef,1}:\n",
       " x_out[1] = 5\n",
       " x_out[2] = 4\n",
       " x_out[3] = 3\n",
       " x_out[4] = 2\n",
       " x_out[5] = 1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test add_output_constraints - Ax = b\n",
    "outputs = [5.0 4.0 3.0 2.0 1.0]\n",
    "m = Model(solver = GLPKSolverLP())\n",
    "add_output_constraints(large_nnet, outputs, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function add_network_constraints(nnet::Network, m::Model)\n",
    "    M = 1 # is this a suitable (\"sufficiently large\") constant?\n",
    "    n_layers = length(nnet.layer_sizes)\n",
    "    @variable(m, x_net[i=1:n_layers, j=1:nnet.layer_sizes[i]])\n",
    "    @variable(m, delta[i=1:n_layers, j=1:nnet.layer_sizes[i]], Bin)\n",
    "    # 3 dimensional array of constraints - 4 for each node\n",
    "    for (l, layer) in enumerate(nnet.layers)\n",
    "        \n",
    "        #@constraint(m, x_n, x[i] >= ((x_n * layer.weights) + layer.biases)[i])\n",
    "        #@constraint(m, x_n, x[i] <= ((x_n * layer.weights) + layer.biases)[i] + M*delta[i])\n",
    "        @constraint(m, x[i] >= 0)\n",
    "        @constraint(m, x_n, x[i] <= M*(1 - delta[i]))  \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_network_constraints(small_nnet, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function initialize_constraints(inputs::Matrix{Float64}, outputs::Matrix{Float64},\n",
    "                                network::Network, m::Model)\n",
    "    add_input_constraints(inputs, m)\n",
    "    #add_output_constraints(outputs, m)\n",
    "    #add_network_constraints(network, m)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our model and add our contraints\n",
    "model = Model(solver = GLPKSolverLP()) # use GLPK LP as our solver\n",
    "initialize_constraints(inputs, outputs, network, model)\n",
    "\n",
    "# Solve the model\n",
    "status = solve(model)\n",
    "\n",
    "# Print out the solution\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
