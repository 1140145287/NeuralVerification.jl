{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating METADATA...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mComputing changes...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mNo packages to install, update or remove\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage JuMP is already installed\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage GLPKMathProgInterface is already installed\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage Cpp is already installed\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage Cxx is already installed\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "Pkg.update() \n",
    "Pkg.add(\"JuMP\")\n",
    "Pkg.add(\"GLPKMathProgInterface\")\n",
    "Pkg.add(\"Cpp\")\n",
    "Pkg.add(\"Cxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using MathProgBase\n",
    "using GLPKMathProgInterface\n",
    "using Cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"util.jl\")\n",
    "include(\"network.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(Layer[Layer([0.22763; -0.188762; … ; -0.44755; 0.175917], [0.0540062 0.0540062 … -0.180027 0.242194; -1.12374 -1.12374 … -0.00917929 0.055623; … ; -1.57631 -1.57631 … -0.00832176 -0.0926607; 0.620367 0.620367 … -0.0146141 0.262575]), Layer([0.08355; -0.0213261; … ; -0.426623; 0.780925], [-0.184202 -0.184202 … 0.337388 0.395671; 0.0171639 0.0171639 … -0.0371157 0.0196442; … ; -1.24508 -1.24508 … 0.646698 -0.159838; -0.348713 -0.348713 … -0.60238 -0.142155]), Layer([-0.408486; 1.06875; … ; -0.464336; 0.114195], [0.146062 0.146062 … -1.15657 0.515279; -1.159 -1.159 … -2.33211 -0.517898; … ; -1.14982 -1.14982 … -1.17371 0.414968; -0.684643 -0.684643 … -0.064733 -0.186417]), Layer([1.48416; -0.0392727; … ; 0.0762837; -0.216393], [-0.775044 -0.775044 … 0.00288769 -0.0587614; -0.289933 -0.289933 … 0.0289771 0.0943521; … ; 0.124486 0.124486 … -0.0140547 0.0703901; 0.0862763 0.0862763 … 0.0219731 -0.0403008]), Layer([0.343884; -0.148704; … ; -0.331041; -0.654165], [-0.169473 -0.169473 … -0.0158796 0.271254; 0.143577 0.143577 … -0.00813101 -0.193434; … ; 0.233909 0.233909 … -0.0408955 -1.33666; 0.19239 0.19239 … 0.0402966 -0.291227]), Layer([-0.430061; -0.0245742; … ; -0.114347; 0.121706], [0.0198897 0.0198897 … -0.556117 -0.321128; -0.12478 -0.12478 … 0.0824242 0.0293015; … ; -0.283984 -0.283984 … 0.0293453 -0.0325373; 0.0114592 0.0114592 … -0.0156882 -0.00548695]), Layer([-0.0102815; -0.0158668; … ; -0.015336; -0.0148281], [-0.0010049 -0.0010049 … -0.00114841 0.0116412; -0.00160923 -0.00160923 … -0.0515162 0.011273; … ; 0.00386038 0.00386038 … -0.0582468 -0.0100225; 0.032974 0.032974 … -0.00340823 0.0212921])], [5, 50, 50, 50, 50, 50, 50, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in neural networks\n",
    "small_nnet = read_nnet(\"small_nnet.txt\")\n",
    "large_nnet = read_nnet(\"ACASXU_nnet_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_input_constraints (generic function with 1 method)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_input_constraints(nnet::Network, inputs::Matrix{Float64}, m::Model)\n",
    "    n_inputs = nnet.layer_sizes[1]\n",
    "    @variable(m, x_in[1:n_inputs])\n",
    "    @constraint(m, constr_in[i=1:n_inputs], x_in[i] == inputs[i])    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{JuMP.ConstraintRef,1}:\n",
       " x_in[1] = 1\n",
       " x_in[2] = 2\n",
       " x_in[3] = 3\n",
       " x_in[4] = 4\n",
       " x_in[5] = 5"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test add input constraints\n",
    "inputs = [1.0 2.0 3.0 4.0 5.0]\n",
    "m = Model(solver = GLPKSolverLP())\n",
    "add_input_constraints(large_nnet, inputs, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_output_constraints (generic function with 1 method)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_output_constraints(nnet::Network, outputs::Matrix{Float64}, m::Model)\n",
    "    n_layers = length(nnet.layer_sizes)\n",
    "    n_outputs = nnet.layer_sizes[n_layers]\n",
    "    @variable(m, x_out[1:n_outputs])\n",
    "    @constraint(m, constr_out[i=1:n_outputs], x_out[i] == outputs[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{JuMP.ConstraintRef,1}:\n",
       " x_out[1] = 5\n",
       " x_out[2] = 4\n",
       " x_out[3] = 3\n",
       " x_out[4] = 2\n",
       " x_out[5] = 1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test add_output_constraints\n",
    "outputs = [5.0 4.0 3.0 2.0 1.0]\n",
    "m = Model(solver = GLPKSolverLP())\n",
    "add_output_constraints(large_nnet, outputs, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_network_constraints (generic function with 1 method)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_network_constraints(nnet::Network, m::Model)\n",
    "    M = 1 # is this a suitable (\"sufficiently large\") constant?\n",
    "    n_layers = length(nnet.layer_sizes)\n",
    "    @variable(m, x_net[i=1:n_layers, j=1:nnet.layer_sizes[i]])\n",
    "    @variable(m, delta[i=1:n_layers, j=1:nnet.layer_sizes[i]], Bin)\n",
    "    for (l, layer) in enumerate(nnet.layers)\n",
    "        \n",
    "        #@constraint(m, x_n, x[i] >= ((x_n * layer.weights) + layer.biases)[i])\n",
    "        #@constraint(m, x_n, x[i] <= ((x_n * layer.weights) + layer.biases)[i] + M*delta[i])\n",
    "        @constraint(m, , x[i] >= 0)\n",
    "        @constraint(m, x_n, x[i] <= M*(1 - delta[i]))  \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mA variable or constraint named x_net is already attached to this model. If creating variables programmatically, use the anonymous variable syntax x = @variable(m, [1:N], ...).\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$ delta_{i,j} \\in \\{0,1\\} \\quad\\forall i \\in \\{1,2,3,4\\}, j \\in \\{\\dots\\} $$"
      ],
      "text/plain": [
       "delta[i,j] ∈ {0,1} ∀ i ∈ {1,2,3,4}, j ∈ {…}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_network_constraints(small_nnet, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function initialize_constraints(inputs::Matrix{Float64}, outputs::Matrix{Float64},\n",
    "                                network::Network, m::Model)\n",
    "    add_input_constraints(inputs, m)\n",
    "    #add_output_constraints(outputs, m)\n",
    "    #add_network_constraints(network, m)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our model and add our contraints\n",
    "model = Model(solver = GLPKSolverLP()) # use GLPK LP as our solver\n",
    "initialize_constraints(inputs, outputs, network, model)\n",
    "\n",
    "# Solve the model\n",
    "status = solve(model)\n",
    "\n",
    "# Print out the solution\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
