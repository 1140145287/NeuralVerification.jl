{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes while package stuff is sorted out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using JuMP\n",
    "using MathProgBase.SolverInterface\n",
    "using GLPKMathProgInterface\n",
    "using LazySets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partition (generic function with 2 methods)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../src/utils/activation.jl\")\n",
    "include(\"../src/utils/network.jl\")\n",
    "include(\"../src/utils/problem.jl\")\n",
    "include(\"../src/utils/util.jl\")\n",
    "\n",
    "include(\"../src/reachability/maxSens.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{alignat*}{1}\\min\\quad & 0\\\\\n",
       "\\text{Subject to} \\quad\\end{alignat*}\n",
       " $$"
      ],
      "text/plain": [
       "Feasibility problem with:\n",
       " * 0 linear constraints\n",
       " * 0 variables\n",
       "Solver is GLPKInterfaceLP"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_nnet = read_nnet(\"../examples/networks/small_nnet.txt\")\n",
    "\n",
    "A = Array{Float64, 2}(2,1)\n",
    "A[1,1] = 1\n",
    "A[2,1] = -1\n",
    "#inputSet = HPolytope(A, [1.0,3.0])\n",
    "#outputSet = HPolytope(A,[0.0,1000.0])\n",
    "\n",
    "inputSet = Hyperrectangle([1.0, 1.0], [.2, .2])\n",
    "inputSet = Hyperrectangle([2.0,], [100.0])\n",
    "\n",
    "problem = Problem(small_nnet, inputSet, outputSet)\n",
    "solver = GLPKSolverLP(method=:Exact)\n",
    "m = Model(solver=solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init_nnet_vars (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function init_nnet_vars(model::Model, network::Network)\n",
    "    layers = network.layers\n",
    "    #input layer and last layer have b_vars because they are unbounded\n",
    "    b_vars = Vector{Vector{Variable}}(length(layers) + 1) # +1 for input layer\n",
    "    #f_vars are always positive and used as front for ReLUs\n",
    "    f_vars = Vector{Vector{Variable}}(length(layers) -1)\n",
    "    \n",
    "    input_layer_n = size(first(layers).weights, 2)\n",
    "    all_layers_n  = [length(l.bias) for l in layers]\n",
    "    insert!(all_layers_n, 1, input_layer_n)\n",
    "\n",
    "    for (i, n) in enumerate(all_layers_n)\n",
    "        b_vars[i] = @variable(model, [1:n]) # To do: name the variables\n",
    "        if 1 < i < length(layers) + 1\n",
    "            f_vars[i-1] = @variable(model, [1:n])\n",
    "        end\n",
    "    end\n",
    "    return b_vars, f_vars\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that were not included "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_output_constraint (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_input_constraint(model::Model, input::HPolytope, neuron_vars::Vector{Variable})\n",
    "    in_A,  in_b  = tosimplehrep(input)\n",
    "    @constraint(model,  in_A * neuron_vars .<= in_b)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function add_input_constraint(model::Model, input::Hyperrectangle, neuron_vars::Vector{Variable})\n",
    "    @constraint(model,  neuron_vars .<= high(input))\n",
    "    @constraint(model,  neuron_vars .>= low(input))\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function add_output_constraint(model::Model, output::AbstractPolytope, neuron_vars::Vector{Variable})\n",
    "    out_A, out_b = tosimplehrep(output)\n",
    "    @constraint(model, out_A * neuron_vars .<= out_b)\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encode (generic function with 1 method)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function encode(model::Model, problem::Problem, relustatus::Array{Array{Int64,1},1})\n",
    "    #bs, fs = init_nnet_vars(model, problem.network)\n",
    "    \n",
    "    #TEST\n",
    "    bs = [[@variable(m, b11)],\n",
    "         [@variable(m, b21),@variable(m, b22)],\n",
    "         [@variable(m, b31),@variable(m, b32)],  \n",
    "         [@variable(m, b41)]]\n",
    "\n",
    "    fs = [[@variable(m, f21),@variable(m, f22)],\n",
    "          [@variable(m, f31),@variable(m, f32)]]\n",
    "    \n",
    "    #add_input_constraint(model, inputSet, bs[1])\n",
    "    #add_output_constraint(model, problem.output, last(bs))\n",
    "\n",
    "    for (i, layer) in enumerate(problem.network.layers)\n",
    "        #print(string(\"i: \",i))\n",
    "        (W, b, act) = (layer.weights, layer.bias, layer.activation)\n",
    "        #before_act = W * neurons[i] + b\n",
    "        \n",
    "        #first layer is different\n",
    "        if i == 1\n",
    "            for j in 1:length(layer.bias)\n",
    "               @constraint(model, -bs[2][j] + bs[1][1]*W[j] == -b[j]) \n",
    "            end\n",
    "        elseif 1<i\n",
    "            for j in 1:length(layer.bias) # For evey node\n",
    "                @constraint(model, -bs[i+1][j] + dot(fs[i-1],W[j,:]) == -b[j])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Adding linear constraints\n",
    "    \n",
    "    #first layer\n",
    "    bounds = get_bounds(problem)\n",
    "    \n",
    "    \n",
    "    #@constraint(model, bs[1] .<= bounds[1].center + bounds[1].radius)\n",
    "    #@constraint(model, bs[1] .>= bounds[1].center - bounds[1].radius)\n",
    "    \n",
    "    for i in 1:length(bs)\n",
    "        @constraint(model, bs[i] .<= bounds[i].center + bounds[i].radius)\n",
    "        @constraint(model, bs[i] .>= bounds[i].center - bounds[i].radius)\n",
    "    end\n",
    "    \n",
    "    # positivity contraint for f variables\n",
    "    for i in 1:length(fs)\n",
    "        @constraint(model, fs[i] .>= zeros(length(fs[i])))\n",
    "    end\n",
    "    # Objective: Lâˆž norm of the disturbance\\\n",
    "    @objective(m, Max, 0)\n",
    "    return (bs, fs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LazySets.Hyperrectangle{Float64}([1260.5], [1242.0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bounds(problem)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 2502.5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bounds(problem)[4].center + get_bounds(problem)[4].radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 18.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bounds(problem)[4].center -  get_bounds(problem)[4].radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array{JuMP.Variable,1}[JuMP.Variable[b11], JuMP.Variable[b21, b22], JuMP.Variable[b31, b32], JuMP.Variable[b41]], Array{JuMP.Variable,1}[JuMP.Variable[f21, f22], JuMP.Variable[f31, f32]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Model(solver = GLPKSolverLP(method=:Exact))\n",
    "#bs, fs = init_nnet_vars(m, problem.network)\n",
    "bs, fs = encode(m, problem, [[1,1], [1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{alignat*}{1}\\max\\quad & 0\\\\\n",
       "\\text{Subject to} \\quad & -b21 + b11 = -1.5\\\\\n",
       " & -b22 + b11 = -1.5\\\\\n",
       " & -b31 + 2 f21 + 2 f22 = -2.5\\\\\n",
       " & -b32 + 2 f21 + 2 f22 = -2.5\\\\\n",
       " & -b41 + 3 f31 + 3 f32 = -3.5\\\\\n",
       " & b11 \\leq 102\\\\\n",
       " & b11 \\geq -98\\\\\n",
       " & b21 \\leq 103.5\\\\\n",
       " & b22 \\leq 103.5\\\\\n",
       " & b21 \\geq 0\\\\\n",
       " & b22 \\geq 0\\\\\n",
       " & b31 \\leq 416.5\\\\\n",
       " & b32 \\leq 416.5\\\\\n",
       " & b31 \\geq 2.5\\\\\n",
       " & b32 \\geq 2.5\\\\\n",
       " & b41 \\leq 2502.5\\\\\n",
       " & b41 \\geq 18.5\\\\\n",
       " & f21 \\geq 0\\\\\n",
       " & f22 \\geq 0\\\\\n",
       " & f31 \\geq 0\\\\\n",
       " & f32 \\geq 0\\\\\n",
       " & b11\\\\\n",
       " & b21\\\\\n",
       " & b22\\\\\n",
       " & b31\\\\\n",
       " & b32\\\\\n",
       " & b41\\\\\n",
       " & f21\\\\\n",
       " & f22\\\\\n",
       " & f31\\\\\n",
       " & f32\\\\\n",
       "\\end{alignat*}\n",
       " $$"
      ],
      "text/plain": [
       "Maximization problem with:\n",
       " * 21 linear constraints\n",
       " * 10 variables\n",
       "Solver is GLPKInterfaceLP"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":Optimal"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JuMP.solve(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ JuMP.Variable[b11] $$"
      ],
      "text/plain": [
       "1-element Array{JuMP.Variable,1}:\n",
       " b11"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Array{Float64,1},1}:\n",
       " [0.0, 0.0]\n",
       " [2.5, 2.5]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_test[2:length(b_test)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check_relu_status (generic function with 1 method)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function check_relu_status(bs::Array{Array{JuMP.Variable,1},1}, \n",
    "        fs::Array{Array{JuMP.Variable,1},1})\n",
    "    b_values = [getvalue(b) for b in bs[2:length(bs)-1]]\n",
    "    f_values = [getvalue(f) for f in fs]\n",
    "    return [x[1] .== x[2] for x in zip(b_values, f_values)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function fix_broken_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function reluplexrun"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
