<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Helper Functions · NeuralVerification.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>NeuralVerification.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">NeuralVerification.jl</a></li><li><a class="toctext" href="../problem/">Problem Definitions</a></li><li><a class="toctext" href="../solvers/">Solvers</a></li><li class="current"><a class="toctext" href>Helper Functions</a><ul class="internal"></ul></li><li><a class="toctext" href="../existing_implementations/">Existing Implementations</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Helper Functions</a></li></ul><a class="edit-page" href="https://github.com/sisl/NeuralVerification.jl/blob/master/docs/src/functions.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Helper Functions</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Helper-Functions-1" href="#Helper-Functions-1">Helper Functions</a></h1><p><a href="TODO: can rename helper to whatever makes the most sense"></a></p><p><a href="```@contents"></a> <a href="    Pages = [&quot;functions.md&quot;]"></a> <a href="    Depth = 3"></a> <a href="```"></a></p><p><a href="TODO: Since most of these function are not exported they have to be called with NeuralVerification.[]"></a> <a href="Should consider whether we want to list unexported functions online at all."></a></p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NeuralVerification.read_nnet" href="#NeuralVerification.read_nnet"><code>NeuralVerification.read_nnet</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">read_nnet(fname::String; last_layer_activation = Id())</code></pre><p>Read in neural net from a <code>.nnet</code> file and return Network struct. The <code>.nnet</code> format is borrowed from <a href="https://github.com/sisl/NNet">NNet</a>. The format assumes all hidden layers have ReLU activation. Keyword argument <code>last_layer_activation</code> sets the activation of the last layer, and defaults to <code>Id()</code>, (i.e. a linear output layer).</p></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L1-L9">source</a></section><div class="admonition warning"><div class="admonition-title">Missing docstring.</div><div class="admonition-text"><p>Missing docstring for <code>NeuralVerification.init_layer</code>. Check Documenter&#39;s build log for details.</p></div></div><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NeuralVerification.compute_output" href="#NeuralVerification.compute_output"><code>NeuralVerification.compute_output</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">compute_output(nnet::Network, input::Vector{Float64})</code></pre><p>Propagate a given vector through a nnet and compute the output.</p></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L50-L54">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NeuralVerification.get_activation" href="#NeuralVerification.get_activation"><code>NeuralVerification.get_activation</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">get_activation(L, x::Vector)</code></pre><p>Finds the activation pattern of a vector <code>x</code> subject to the activation function given by the layer <code>L</code>. Returns a Vector{Bool} where <code>true</code> denotes the node is &quot;active&quot;. In the sense of ReLU, this would be <code>x[i] &gt;= 0</code>.</p></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L63-L67">source</a><div><div><pre><code class="language-none">get_activation(nnet::Network, x::Vector)</code></pre><p>Given a network, find the activation pattern of all neurons at a given point x. Returns Vector{Vector{Bool}}. Each Vector{Bool} refers to the activation pattern of a particular layer.</p></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L71-L76">source</a><div><div><pre><code class="language-none">get_activation(nnet::Network, input::Hyperrectangle)</code></pre><p>Given a network, find the activation pattern of all neurons for a given input set. Assume ReLU. return Vector{Vector{Int64}}.</p><ul><li>1: activated</li><li>0: undetermined</li><li>-1: not activated</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L88-L97">source</a><div><div><pre><code class="language-none">get_activation(nnet::Network, bounds::Vector{Hyperrectangle})</code></pre><p>Given a network, find the activation pattern of all neurons given the node-wise bounds. Assume ReLU. return Vector{Vector{Int64}}.</p><ul><li>1: activated</li><li>0: undetermined</li><li>-1: not activated</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L103-L112">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NeuralVerification.get_gradient" href="#NeuralVerification.get_gradient"><code>NeuralVerification.get_gradient</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">get_gradient(nnet::Network, x::Vector)</code></pre><p>Given a network, find the gradient at the input x</p></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L136-L140">source</a><div><div><pre><code class="language-none">get_gradient(nnet::Network, input::AbstractPolytope)</code></pre><p>Get lower and upper bounds on network gradient for a given input set. Return:</p><ul><li><code>LG::Vector{Matrix}</code>: lower bounds</li><li><code>UG::Vector{Matrix}</code>: upper bounds</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L162-L169">source</a><div><div><pre><code class="language-none">get_gradient(nnet::Network, LΛ::Vector{Matrix}, UΛ::Vector{Matrix})</code></pre><p>Get lower and upper bounds on network gradient for given gradient bounds on activations Inputs:</p><ul><li><code>LΛ::Vector{Matrix}</code>: lower bounds on activation gradients</li><li><code>UΛ::Vector{Matrix}</code>: upper bounds on activation gradients</li></ul><p>Return:</p><ul><li><code>LG::Vector{Matrix}</code>: lower bounds</li><li><code>UG::Vector{Matrix}</code>: upper bounds</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L200-L210">source</a><div><div><pre><code class="language-none">get_gradient(nnet::Network, LΛ::Vector{Vector{N}}, UΛ::Vector{Vector{N}}) where N</code></pre><p>Get lower and upper bounds on network gradient for given gradient bounds on activations Inputs:</p><ul><li><code>LΛ::Vector{Vector{N}}</code>: lower bounds on activation gradients</li><li><code>UΛ::Vector{Vector{N}}</code>: upper bounds on activation gradients</li></ul><p>Return:</p><ul><li><code>(LG, UG)</code> lower and upper bounds</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L223-L232">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NeuralVerification.act_gradient" href="#NeuralVerification.act_gradient"><code>NeuralVerification.act_gradient</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">act_gradient(act::ReLU, z_hat::Vector{N}) where N</code></pre><p>Computing the gradient of an activation function at point z_hat. Currently only support ReLU and Id.</p></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L153-L158">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NeuralVerification.act_gradient_bounds" href="#NeuralVerification.act_gradient_bounds"><code>NeuralVerification.act_gradient_bounds</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">act_gradient_bounds(nnet::Network, input::AbstractPolytope)</code></pre><p>Computing the bounds on the gradient of all activation functions given an input set. Currently only support ReLU. Return:</p><ul><li><code>LΛ::Vector{Matrix}</code>: lower bounds</li><li><code>UΛ::Vector{Matrix}</code>: upper bounds</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L175-L183">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NeuralVerification.interval_map" href="#NeuralVerification.interval_map"><code>NeuralVerification.interval_map</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">interval_map(W::Matrix, l, u)</code></pre><p>Simple linear mapping on intervals Inputs:</p><ul><li><code>W::Matrix{N}</code>: linear mapping</li><li><code>l::Vector{N}</code>: lower bound</li><li><code>u::Vector{N}</code>: upper bound</li></ul><p>Outputs:</p><ul><li><code>(lbound, ubound)</code> (after the mapping)</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L245-L255">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NeuralVerification.get_bounds" href="#NeuralVerification.get_bounds"><code>NeuralVerification.get_bounds</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">get_bounds(problem::Problem)
get_bounds(nnet::Network, input::Hyperrectangle)</code></pre><p>This function calls maxSens to compute node-wise bounds given a input set.</p><p>Return:</p><ul><li><code>Vector{Hyperrectangle}</code>: bounds for all nodes <strong>after</strong> activation. <code>bounds[1]</code> is the input set.</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L262-L270">source</a></section><div class="admonition warning"><div class="admonition-title">Missing docstring.</div><div class="admonition-text"><p>Missing docstring for <code>NeuralVerification.linear_transformation</code>. Check Documenter&#39;s build log for details.</p></div></div><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="NeuralVerification.split_interval" href="#NeuralVerification.split_interval"><code>NeuralVerification.split_interval</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">split_interval(dom, i)</code></pre><p>Split a set into two at the given index.</p><p>Inputs:</p><ul><li><code>dom::Hyperrectangle</code>: the set to be split</li><li><code>i</code>: the index to split at</li></ul><p>Return:</p><ul><li><code>(left, right)::Tuple{Hyperrectangle, Hyperrectangle}</code>: two sets after split</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/sisl/NeuralVerification.jl/blob/910140c1b251e045cdad6104daec1fceb0bb5d7f/src/utils/util.jl#L332-L342">source</a></section><footer><hr/><a class="previous" href="../solvers/"><span class="direction">Previous</span><span class="title">Solvers</span></a><a class="next" href="../existing_implementations/"><span class="direction">Next</span><span class="title">Existing Implementations</span></a></footer></article></body></html>
